{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1=np.random.random(size=(1000,1000))\n",
    "matrix2=np.random.random(size=(1000,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"hdf5_data.h5\",\"w\") as f:\n",
    "    f.create_dataset(\"dataset1\",data=matrix1)\n",
    "    f.create_dataset(\"dataset2\",data=matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from hdf5 data file\n",
    "\n",
    "\n",
    "f=h5py.File(\"hdf5_data.h5\",\"r\")\n",
    "ls=list(f.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=f.get(\"dataset1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create groups and subgroup inside hdf5 file.\n",
    "\n",
    "matrix1=np.random.random(size=(1000,1000))\n",
    "matrix2=np.random.random(size=(1000,1000))\n",
    "matrix3=np.random.random(size=(1000,1000))\n",
    "matrix4=np.random.random(size=(1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"hdf5_group.h5\",\"w\") as f:\n",
    "    G1=f.create_group(\"Group1\")\n",
    "    G1.create_dataset(\"dataset1\",data=matrix1,compression=\"gzip\",compression_opts=9)\n",
    "    G1.create_dataset(\"dataset4\",data=matrix3,compression=\"gzip\",compression_opts=9)\n",
    "    \n",
    "    G21=f.create_group(\"Group2/SubGroup1\")\n",
    "    G21.create_dataset(\"dataset3\",data=matrix4,compression=\"gzip\",compression_opts=9)\n",
    "    \n",
    "    G22=f.create_group(\"Group2/SubGroup2\")\n",
    "    G22.create_dataset(\"dataset2\",data=matrix2,compression=\"gzip\",compression_opts=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read groups from hdf5 files:\n",
    "\n",
    "with h5py.File(\"hdf5_group.h5\",\"r\") as f:\n",
    "    base_item=list(f.items())\n",
    "    print(base_item, \"\\n\")\n",
    "    G2=f.get(\"Group2\")\n",
    "    G2_items=list(G2.items())\n",
    "    print(\"items in group_2:\",G2_items)\n",
    "    G21=G2.get(\"/Group2/SubGroup1\")\n",
    "    G21_items=list(G21.items())\n",
    "    print(G21_items,\"\\n\")\n",
    "    dataset3=np.array(G21.get(\"dataset3\"))\n",
    "    print(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"hdf5_group.h5\",\"r\") as f:\n",
    "    base_item=list(f.items())\n",
    "    print(base_item)\n",
    "    G1=f.get(\"Group1\")\n",
    "    G1_items=list(G1.items())\n",
    "    print(\"items in group_1:\",G1_items)\n",
    "    dataset4=np.array(G1.get(\"dataset4\"))\n",
    "    print(dataset4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading attributes using hdf5\n",
    "\n",
    "\n",
    "matrix1=np.random.random(size=(1000,1000))\n",
    "matrix2=np.random.random(size=(1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create hdf5 file\n",
    "hdf = h5py.File(\"Hdf5_dataset.h5\",\"w\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the datasets\n",
    "dataset1=hdf.create_dataset(\"dataset1\",data=matrix1)\n",
    "dataset2=hdf.create_dataset(\"dataset2\",data=matrix2)\n",
    "#set attributes\n",
    "dataset1.attrs[\"CLASS\"] = \"DATA MATRIX\"\n",
    "\n",
    "dataset1.attrs[\"VERSION\"] = \"1.1\"\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = h5py.File(\"Hdf5_dataset.h5\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=list(hdf.keys())\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=hdf.get(\"dataset1\")\n",
    "dataset1=np.array(data)\n",
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=list(data.attrs.keys())\n",
    "v=list(data.attrs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.attrs[k[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create hdf5 using pandas:\n",
    "import pandas as pd\n",
    "hdf_p=pd.HDFStore('hdf5_pandas.h5',\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"banklist.csv\",encoding=\"windows-1252\")\n",
    "df\n",
    "hdf_p.put(\"DF1\",df1,format=\"table\",data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "    \"active\": True,\n",
    "    \"formed\": 2016,\n",
    "    \"homeTown\": \"Metro City\",\n",
    "    \"members\": [\n",
    "        {\n",
    "            \"age\": 29,\n",
    "            \"name\": \"Molecule Man\",\n",
    "            \"powers\": [\n",
    "                \"Radiation resistance\",\n",
    "                \"Turning tiny\",\n",
    "                \"Radiation blast\"\n",
    "            ],\n",
    "            \"secretIdentity\": \"Dan Jukes\"\n",
    "        },\n",
    "        {\n",
    "            \"age\": 39,\n",
    "            \"name\": \"Madame Uppercut\",\n",
    "            \"powers\": [\n",
    "                \"Million tonne punch\",\n",
    "                \"Damage resistance\",\n",
    "                \"Superhuman reflexes\"\n",
    "            ],\n",
    "            \"secretIdentity\": \"Jane Wilson\"\n",
    "        },\n",
    "        {\n",
    "            \"age\": 1000000,\n",
    "            \"name\": \"Eternal Flame\",\n",
    "            \"powers\": [\n",
    "                \"Immortality\",\n",
    "                \"Heat Immunity\",\n",
    "                \"Inferno\",\n",
    "                \"Teleportation\",\n",
    "                \"Interdimensional travel\"\n",
    "            ],\n",
    "            \"secretIdentity\": \"Will Smith\"\n",
    "        }\n",
    "    ],\n",
    "    \"secretBase\": \"Super tower\",\n",
    "    \"squadName\": \"Super Hero Squad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(data)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"members\"].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.concat([df2[\"members\"].apply(pd.Series),df2.drop(\"members\",axis=1)],axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_p.put(\"DF2\",df2,data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_p.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp=pd.HDFStore('hdf5_pandas.h5',mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fp.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=fp.get('/DF1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
